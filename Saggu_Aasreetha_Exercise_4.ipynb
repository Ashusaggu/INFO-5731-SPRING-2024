{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashusaggu/INFO-5731-SPRING-2024/blob/main/Saggu_Aasreetha_Exercise_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 4**\n",
        "\n",
        "**This exercise will provide a valuable learning experience in working with text data and extracting features using various topic modeling algorithms. Key concepts such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), lda2vec, and BERTopic.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "\n",
        "**Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "text=[\"recent year global conversation surrounding sustainability intensified growing emphasis reducing carbon footprint\",\n",
        "    \"transportation sector known significant contribution pollution seen surge adoption sustainable mobility solution electric bus car sharing micro mobility emerged key player reshaping navigate urban landscape\",\n",
        "    \"electric bus backbone eco friendly public transportation\",\n",
        "    \"bustling city hum traditional bus gradually replaced whisper electric bus vehicle represent fundamental shift public transportation offering environmentally friendly alternative gas guzzling counterpart\",\n",
        "    \"electric bus run rechargeable battery emitting zero tailpipe emission reducing noise pollution making promising solution tackling air quality issue densely populated area\",\n",
        "    \"integration electric bus public transportation network yielded remarkable result contribute cleaner air also provide smoother quieter ride passenger\",\n",
        "    \"advancement battery technology range efficiency electric bus improved significantly addressing concern regarding operational capability potential limitation\",\n",
        "    \"car sharing driving towards sustainable future\",\n",
        "    \"urban population continue swell demand convenient cost effective transportation option led rise car sharing service\",\n",
        "    \"car sharing program enable individual access vehicle needed basis eliminating need personal car ownership\",\n",
        "    \"encouraging resource sharing reducing number car road initiative play vital role promoting sustainable mobility\",\n",
        "    \"benefit car sharing extend beyond environmental conservation include reduced traffic congestion minimized parking space requirement lower overall transportation cost user\",\n",
        "    \"furthermore incorporation electric hybrid vehicle within car sharing fleet bolstered sustainability quotient offering user eco friendly alternative transportation need\",\n",
        "    \"micro mobility redefining short distance travel\",\n",
        "    \"bustling city center street witnessed emergence new mode transportation micro mobility\",\n",
        "    \"term encompasses various compact lightweight mode transport electric scooter bicycle even electric skateboard\",\n",
        "    \"designed short distance travel alternative provide convenient eco conscious solution navigating congested urban area\",\n",
        "    \"rising popularity micro mobility option attributed accessibility flexibility user friendly nature\",\n",
        "    \"alternative provide effective mean traversing short distance lessening dependence traditional transportation method daily commute\",\n",
        "    \"moreover eco friendly nature resonates increasing focus curbing carbon emission fostering sustainable development urban area\",\n",
        "    \"role infrastructure policy promoting sustainable mobility\",\n",
        "    \"effectiveness sustainable mobility solution heavily relies existence supportive infrastructure conducive policy\",\n",
        "    \"proliferation solution positive step success contingent presence appropriate infrastructure well designed policy\",\n",
        "    \"developing charging infrastructure electric bus vehicle along implementation dedicated lane parking space vital promoting widespread adoption eco friendly transportation option\",\n",
        "    \"furthermore policy initiative aimed incentivizing use sustainable mobility solution tax benefit electric vehicle user integration car sharing service urban planning strategy significantly influence consumer behavior encourage transition towards sustainable transportation practice\",\n",
        "    \"challenge opportunity horizon\",\n",
        "    \"despite evident benefit sustainable mobility solution several challenge persist widespread implementation\",\n",
        "    \"challenge include initial cost associated infrastructure development need continued technological advancement enhance efficiency electric vehicle requirement comprehensive regulatory framework govern operation car sharing micro mobility service\",\n",
        "    \"however challenge also present opportunity innovation collaboration within public private sector\",\n",
        "    \"investment research development coupled strategic partnership government business community pave way seamless integration sustainable mobility solution fabric urban life\",\n",
        "    \"sustainable future motion\",\n",
        "    \"era impact climate change environmental decline loom large importance sustainable mobility solution become ever evident\",\n",
        "    \"embracing capability electric bus car sharing micro mobility enable city cultivate transportation ecosystem cleaner efficient also inclusive benefiting environment people inhabit\",\n",
        "    \"journey towards sustainable mobility requires collective effort stakeholder across various sector playing pivotal role driving positive change\",\n",
        "    \"continued innovation investment advocacy pave way future mobility efficient accessible also sustainable environmentally conscious\",\n",
        "    \"together steer city toward sustainable vibrant tomorrow\",\n",
        "    \"empowering community education engagement\",\n",
        "    \"fostering community empowerment education engagement form cornerstone successful sustainable mobility solution\",\n",
        "    \"educational program awareness campaign instrumental cultivating culture sustainability encouraging individual make informed choice transportation habit\",\n",
        "    \"highlighting benefit environmentally friendly alternative showcasing positive impact environment community inspired actively participate transition towards sustainable mobility\",\n",
        "    \"moreover community engagement initiative serve platform gathering valuable feedback insight resident enabling policymaker transportation authority tailor strategy solution according specific need preference local populace\",\n",
        "    \"incorporating community input planning development sustainable mobility project city ensure effort effective also inclusive community centric\",\n",
        "    \"looking ahead evolution sustainable mobility\",\n",
        "    \"technology continues advance societal awareness environmental issue grow landscape sustainable mobility poised evolution\",\n",
        "    \"continued research development field electric vehicle technology battery efficiency renewable energy source expected drive significant improvement performance accessibility sustainable transportation option\",\n",
        "    \"furthermore integration smart technology data driven solution hold potential optimize efficiency public transportation network enhance user experience car sharing service streamline operation micro mobility initiative\",\n",
        "    \"leveraging power data analytics city make data driven decision lead effective sustainable mobility solution ultimately contributing cleaner resilient urban environment\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'text': text})\n",
        "df.to_csv('text_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bIq4aX82GuXk",
        "outputId": "c6a7e20f-d70d-4fc2-abcb-0871ed6a8c12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  recent year global conversation surrounding su...\n",
              "1  transportation sector known significant contri...\n",
              "2  electric bus backbone eco friendly public tran...\n",
              "3  bustling city hum traditional bus gradually re...\n",
              "4  electric bus run rechargeable battery emitting..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98c55699-513f-4bc6-b8d9-071c5a254397\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>recent year global conversation surrounding su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>transportation sector known significant contri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>electric bus backbone eco friendly public tran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bustling city hum traditional bus gradually re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>electric bus run rechargeable battery emitting...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98c55699-513f-4bc6-b8d9-071c5a254397')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98c55699-513f-4bc6-b8d9-071c5a254397 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98c55699-513f-4bc6-b8d9-071c5a254397');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7143058a-2dfe-47fa-8b9b-e4cafcaff9fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7143058a-2dfe-47fa-8b9b-e4cafcaff9fb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7143058a-2dfe-47fa-8b9b-e4cafcaff9fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 47,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"challenge include initial cost associated infrastructure development need continued technological advancement enhance efficiency electric vehicle requirement comprehensive regulatory framework govern operation car sharing micro mobility service\",\n          \"highlighting benefit environmentally friendly alternative showcasing positive impact environment community inspired actively participate transition towards sustainable mobility\",\n          \"despite evident benefit sustainable mobility solution several challenge persist widespread implementation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "!python3 -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InqN6WRnHBhO",
        "outputId": "afb4965e-51a3-4e61-e3ee-5edfffc03d6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L45Y1265HtSO",
        "outputId": "f57f57a3-0164-454d-cb39-17e8dc66dc40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.2.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.9.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.4.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "import gensim #code for gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# For lemmetization we use spacy\n",
        "import spacy\n",
        "\n",
        "# tools used for plotting: pyLDAvis , matplotlib\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n"
      ],
      "metadata": {
        "id": "d4Qg8gSGHBkR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = df.text.tolist()#converts our dataframe to list\n",
        "data = [re.sub(\"\\'\", \"\", word) for word in data]#removes if there are any single quotes in the data.\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3g4DqjIHBn6",
        "outputId": "fe5f5560-73fa-4aa0-cc22-8a02ab16c79f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['recent year global conversation surrounding sustainability intensified growing emphasis reducing carbon footprint', 'transportation sector known significant contribution pollution seen surge adoption sustainable mobility solution electric bus car sharing micro mobility emerged key player reshaping navigate urban landscape', 'electric bus backbone eco friendly public transportation', 'bustling city hum traditional bus gradually replaced whisper electric bus vehicle represent fundamental shift public transportation offering environmentally friendly alternative gas guzzling counterpart', 'electric bus run rechargeable battery emitting zero tailpipe emission reducing noise pollution making promising solution tackling air quality issue densely populated area', 'integration electric bus public transportation network yielded remarkable result contribute cleaner air also provide smoother quieter ride passenger', 'advancement battery technology range efficiency electric bus improved significantly addressing concern regarding operational capability potential limitation', 'car sharing driving towards sustainable future', 'urban population continue swell demand convenient cost effective transportation option led rise car sharing service', 'car sharing program enable individual access vehicle needed basis eliminating need personal car ownership', 'encouraging resource sharing reducing number car road initiative play vital role promoting sustainable mobility', 'benefit car sharing extend beyond environmental conservation include reduced traffic congestion minimized parking space requirement lower overall transportation cost user', 'furthermore incorporation electric hybrid vehicle within car sharing fleet bolstered sustainability quotient offering user eco friendly alternative transportation need', 'micro mobility redefining short distance travel', 'bustling city center street witnessed emergence new mode transportation micro mobility', 'term encompasses various compact lightweight mode transport electric scooter bicycle even electric skateboard', 'designed short distance travel alternative provide convenient eco conscious solution navigating congested urban area', 'rising popularity micro mobility option attributed accessibility flexibility user friendly nature', 'alternative provide effective mean traversing short distance lessening dependence traditional transportation method daily commute', 'moreover eco friendly nature resonates increasing focus curbing carbon emission fostering sustainable development urban area', 'role infrastructure policy promoting sustainable mobility', 'effectiveness sustainable mobility solution heavily relies existence supportive infrastructure conducive policy', 'proliferation solution positive step success contingent presence appropriate infrastructure well designed policy', 'developing charging infrastructure electric bus vehicle along implementation dedicated lane parking space vital promoting widespread adoption eco friendly transportation option', 'furthermore policy initiative aimed incentivizing use sustainable mobility solution tax benefit electric vehicle user integration car sharing service urban planning strategy significantly influence consumer behavior encourage transition towards sustainable transportation practice', 'challenge opportunity horizon', 'despite evident benefit sustainable mobility solution several challenge persist widespread implementation', 'challenge include initial cost associated infrastructure development need continued technological advancement enhance efficiency electric vehicle requirement comprehensive regulatory framework govern operation car sharing micro mobility service', 'however challenge also present opportunity innovation collaboration within public private sector', 'investment research development coupled strategic partnership government business community pave way seamless integration sustainable mobility solution fabric urban life', 'sustainable future motion', 'era impact climate change environmental decline loom large importance sustainable mobility solution become ever evident', 'embracing capability electric bus car sharing micro mobility enable city cultivate transportation ecosystem cleaner efficient also inclusive benefiting environment people inhabit', 'journey towards sustainable mobility requires collective effort stakeholder across various sector playing pivotal role driving positive change', 'continued innovation investment advocacy pave way future mobility efficient accessible also sustainable environmentally conscious', 'together steer city toward sustainable vibrant tomorrow', 'empowering community education engagement', 'fostering community empowerment education engagement form cornerstone successful sustainable mobility solution', 'educational program awareness campaign instrumental cultivating culture sustainability encouraging individual make informed choice transportation habit', 'highlighting benefit environmentally friendly alternative showcasing positive impact environment community inspired actively participate transition towards sustainable mobility', 'moreover community engagement initiative serve platform gathering valuable feedback insight resident enabling policymaker transportation authority tailor strategy solution according specific need preference local populace', 'incorporating community input planning development sustainable mobility project city ensure effort effective also inclusive community centric', 'looking ahead evolution sustainable mobility', 'technology continues advance societal awareness environmental issue grow landscape sustainable mobility poised evolution', 'continued research development field electric vehicle technology battery efficiency renewable energy source expected drive significant improvement performance accessibility sustainable transportation option', 'furthermore integration smart technology data driven solution hold potential optimize efficiency public transportation network enhance user experience car sharing service streamline operation micro mobility initiative', 'leveraging power data analytics city make data driven decision lead effective sustainable mobility solution ultimately contributing cleaner resilient urban environment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_to_words(sen):\n",
        "    for s in sen:\n",
        "        yield(gensim.utils.simple_preprocess(str(s), deacc=True)) #deacc= true is used to remove the punctuations\n",
        "words = list(sentence_to_words(data))\n",
        "\n",
        "print(words[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmA34P0LHB7v",
        "outputId": "f05bb7bb-6631-4fc3-fed6-9c2ee3f69d12"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['recent', 'year', 'global', 'conversation', 'surrounding', 'sustainability', 'intensified', 'growing', 'emphasis', 'reducing', 'carbon', 'footprint']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPeQexsSOTut",
        "outputId": "edf2c4ab-3225-4c88-ae68-12771424f560"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bg = gensim.models.Phrases(words, min_count=5, threshold=100) # higher the threshold value , lower the phrases are.\n",
        "tg= gensim.models.Phrases(bg[words], threshold=100)\n",
        "\n",
        "bg_model = gensim.models.phrases.Phraser(bg)\n",
        "tg_model = gensim.models.phrases.Phraser(tg)\n",
        "def remove_stopwords(t):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in t]\n",
        "\n",
        "def bigrams(t):\n",
        "    return [bg_model[doc] for doc in t]\n",
        "\n",
        "def trigrams(t):\n",
        "    return [tg_model[bg_model[doc]] for doc in t]\n",
        "\n",
        "def lemma(t, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_op = []\n",
        "    for sent in t:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_op.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_op\n",
        "data_words_nostops = remove_stopwords(words)\n",
        "\n",
        "data_words_bigrams = bigrams(data_words_nostops)\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "lemm_data = lemma(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(lemm_data[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL-AWSqMHB-m",
        "outputId": "e057ad4e-5314-4bdb-d4fa-246c63648933"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['recent', 'year', 'global', 'conversation', 'surround', 'sustainability', 'intensify', 'grow', 'emphasis', 'reduce', 'carbon', 'footprint']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_word = corpora.Dictionary(lemm_data)\n",
        "review_text = lemm_data\n",
        "corpus = [review_word.doc2bow(text) for text in review_text]\n",
        "print(corpus[:1])\n",
        "[[(review_word[i], f) for i, f in c] for c in corpus[:1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yOjwf9SHCBM",
        "outputId": "9dd2edf6-7755-46e0-ca6b-c05eeeff5058"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('carbon', 1),\n",
              "  ('conversation', 1),\n",
              "  ('emphasis', 1),\n",
              "  ('footprint', 1),\n",
              "  ('global', 1),\n",
              "  ('grow', 1),\n",
              "  ('intensify', 1),\n",
              "  ('recent', 1),\n",
              "  ('reduce', 1),\n",
              "  ('surround', 1),\n",
              "  ('sustainability', 1),\n",
              "  ('year', 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(review_word[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSpR_VN5HCDz",
        "outputId": "789cd40a-dcde-4d13-f278-19e8cc139dee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sustainability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "lda_ = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=review_word,\n",
        "                                           num_topics=20,\n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "pprint(lda_.print_topics())\n",
        "doc_lda = lda_[corpus]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr3ZGWqgHCGI",
        "outputId": "d2832c17-f145-4412-cc49-018e220c2dab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.003*\"framework\" + 0.003*\"comprehensive\" + 0.003*\"however\" + '\n",
            "  '0.003*\"collaboration\" + 0.003*\"technological\" + 0.003*\"regulatory\" + '\n",
            "  '0.003*\"operation\" + 0.003*\"initial\" + 0.003*\"govern\" + 0.003*\"present\"'),\n",
            " (1,\n",
            "  '0.055*\"datum\" + 0.028*\"contribute\" + 0.028*\"mobility\" + 0.028*\"urban\" + '\n",
            "  '0.028*\"leverage\" + 0.028*\"decision\" + 0.028*\"solution\" + 0.028*\"power\" + '\n",
            "  '0.028*\"make\" + 0.028*\"resilient\"'),\n",
            " (2,\n",
            "  '0.046*\"transportation\" + 0.046*\"electric\" + 0.024*\"friendly\" + '\n",
            "  '0.024*\"public\" + 0.024*\"navigate\" + 0.024*\"mobility\" + 0.024*\"player\" + '\n",
            "  '0.024*\"bus\" + 0.024*\"pollution\" + 0.024*\"sector\"'),\n",
            " (3,\n",
            "  '0.038*\"friendly\" + 0.038*\"bus\" + 0.019*\"emission\" + 0.019*\"focus\" + '\n",
            "  '0.019*\"foster\" + 0.019*\"increase\" + 0.019*\"curb\" + 0.019*\"urban\" + '\n",
            "  '0.019*\"area\" + 0.019*\"nature\"'),\n",
            " (4,\n",
            "  '0.039*\"electric\" + 0.039*\"transportation\" + 0.039*\"bus\" + '\n",
            "  '0.020*\"widespread\" + 0.020*\"parking\" + 0.020*\"develop\" + 0.020*\"dedicate\" + '\n",
            "  '0.020*\"charge\" + 0.020*\"friendly\" + 0.020*\"option\"'),\n",
            " (5,\n",
            "  '0.028*\"continue\" + 0.028*\"expect\" + 0.028*\"efficiency\" + 0.028*\"research\" + '\n",
            "  '0.028*\"energy\" + 0.028*\"accessibility\" + 0.028*\"significant\" + '\n",
            "  '0.028*\"battery\" + 0.028*\"renewable\" + 0.028*\"vehicle\"'),\n",
            " (6,\n",
            "  '0.034*\"daily\" + 0.034*\"traverse\" + 0.034*\"effective\" + 0.034*\"commute\" + '\n",
            "  '0.034*\"traditional\" + 0.034*\"distance\" + 0.034*\"transportation\" + '\n",
            "  '0.034*\"provide\" + 0.034*\"method\" + 0.034*\"dependence\"'),\n",
            " (7,\n",
            "  '0.043*\"mobility\" + 0.043*\"sustainable\" + 0.043*\"community\" + '\n",
            "  '0.029*\"solution\" + 0.029*\"effort\" + 0.029*\"positive\" + 0.015*\"drive\" + '\n",
            "  '0.015*\"development\" + 0.015*\"incorporate\" + 0.015*\"effective\"'),\n",
            " (8,\n",
            "  '0.028*\"sustainable\" + 0.028*\"poise\" + 0.028*\"continue\" + '\n",
            "  '0.028*\"environmental\" + 0.028*\"grow\" + 0.028*\"landscape\" + 0.028*\"various\" '\n",
            "  '+ 0.028*\"evolution\" + 0.028*\"societal\" + 0.028*\"technology\"'),\n",
            " (9,\n",
            "  '0.044*\"mobility\" + 0.023*\"user\" + 0.023*\"nature\" + 0.023*\"popularity\" + '\n",
            "  '0.023*\"accessibility\" + 0.023*\"option\" + 0.023*\"rise\" + 0.023*\"flexibility\" '\n",
            "  '+ 0.023*\"friendly\" + 0.023*\"attribute\"'),\n",
            " (10,\n",
            "  '0.029*\"challenge\" + 0.029*\"solution\" + 0.019*\"infrastructure\" + '\n",
            "  '0.019*\"opportunity\" + 0.019*\"public\" + 0.019*\"enhance\" + 0.019*\"sharing\" + '\n",
            "  '0.019*\"car\" + 0.019*\"service\" + 0.010*\"requirement\"'),\n",
            " (11,\n",
            "  '0.050*\"redefine\" + 0.050*\"distance\" + 0.050*\"travel\" + 0.050*\"short\" + '\n",
            "  '0.002*\"govern\" + 0.002*\"framework\" + 0.002*\"technological\" + '\n",
            "  '0.002*\"regulatory\" + 0.002*\"operation\" + 0.002*\"initial\"'),\n",
            " (12,\n",
            "  '0.028*\"densely\" + 0.027*\"emit\" + 0.027*\"battery\" + 0.027*\"rechargeable\" + '\n",
            "  '0.027*\"make\" + 0.027*\"run\" + 0.027*\"area\" + 0.027*\"noise\" + 0.027*\"reduce\" '\n",
            "  '+ 0.027*\"quality\"'),\n",
            " (13,\n",
            "  '0.059*\"sustainable\" + 0.059*\"mobility\" + 0.030*\"environmentally\" + '\n",
            "  '0.030*\"impact\" + 0.015*\"way\" + 0.015*\"pave\" + 0.015*\"solution\" + '\n",
            "  '0.015*\"investment\" + 0.015*\"community\" + 0.015*\"efficient\"'),\n",
            " (14,\n",
            "  '0.031*\"cultivate\" + 0.031*\"transportation\" + 0.031*\"benefit\" + '\n",
            "  '0.031*\"mobility\" + 0.031*\"sustainable\" + 0.016*\"clean\" + 0.016*\"bus\" + '\n",
            "  '0.016*\"capability\" + 0.016*\"enable\" + 0.016*\"environment\"'),\n",
            " (15,\n",
            "  '0.031*\"electric\" + 0.031*\"sustainable\" + 0.031*\"significantly\" + '\n",
            "  '0.016*\"solution\" + 0.016*\"transportation\" + 0.016*\"car\" + 0.016*\"urban\" + '\n",
            "  '0.016*\"strategy\" + 0.016*\"community\" + 0.016*\"sharing\"'),\n",
            " (16,\n",
            "  '0.051*\"car\" + 0.051*\"sharing\" + 0.034*\"user\" + 0.034*\"transportation\" + '\n",
            "  '0.034*\"future\" + 0.034*\"sustainable\" + 0.017*\"reduce\" + '\n",
            "  '0.017*\"conservation\" + 0.017*\"environmental\" + 0.017*\"cost\"'),\n",
            " (17,\n",
            "  '0.042*\"car\" + 0.042*\"need\" + 0.021*\"city\" + 0.021*\"vehicle\" + '\n",
            "  '0.021*\"ownership\" + 0.021*\"access\" + 0.021*\"carbon\" + '\n",
            "  '0.021*\"sustainability\" + 0.021*\"program\" + 0.021*\"surround\"'),\n",
            " (18,\n",
            "  '0.030*\"transportation\" + 0.030*\"car\" + 0.030*\"sharing\" + 0.030*\"initiative\" '\n",
            "  '+ 0.015*\"convenient\" + 0.015*\"demand\" + 0.015*\"service\" + 0.015*\"role\" + '\n",
            "  '0.015*\"reduce\" + 0.015*\"cost\"'),\n",
            " (19,\n",
            "  '0.003*\"issue\" + 0.003*\"promise\" + 0.003*\"tailpipe\" + 0.003*\"tackle\" + '\n",
            "  '0.003*\"electric\" + 0.003*\"bus\" + 0.003*\"emission\" + 0.003*\"solution\" + '\n",
            "  '0.003*\"populated\" + 0.003*\"air\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_model_lda = CoherenceModel(model=lda_, texts=lemm_data, dictionary=review_word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yijN8rryHCIf",
        "outputId": "d43351d7-5324-4679-e4a2-fd94173470dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.5004516831123411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFdySw0z9ecN",
        "outputId": "f9e81f2c-3213-4d33-8461-9ac75eba05af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "def coherence_value(dictionary, corpus, texts, limit, start=2, step=1):\n",
        "    coh_val = []\n",
        "    model_ = []\n",
        "\n",
        "    for num_topics in range(start, limit + 1, step):\n",
        "        model = gensim.models.LdaModel(corpus=corpus,\n",
        "                                       id2word=dictionary,\n",
        "                                       num_topics=num_topics,\n",
        "                                       random_state=100,\n",
        "                                       update_every=1,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       per_word_topics=True)\n",
        "        model_.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coh_val.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_,coh_val\n",
        "\n",
        "start, limit, step = 2, 20, 2  # Adjust the range as needed\n",
        "model_, coh_val = coherence_value(dictionary=review_word, corpus=corpus, texts=lemm_data, start=start, limit=limit, step=step)\n",
        "\n",
        "cohe_val = []\n",
        "for n, cval in zip(range(start, limit + 1, step), coh_val):\n",
        "    cohe_val.append(round(cval, 4))\n",
        "    print(\"Number of Topics =\", n, \" has Coherence Value of\", round(cval, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzQubuWlGue1",
        "outputId": "9eb8c063-4a9e-4b57-cfba-644ba31d5479"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Topics = 2  has Coherence Value of 0.3544\n",
            "Number of Topics = 4  has Coherence Value of 0.3639\n",
            "Number of Topics = 6  has Coherence Value of 0.3329\n",
            "Number of Topics = 8  has Coherence Value of 0.3613\n",
            "Number of Topics = 10  has Coherence Value of 0.3652\n",
            "Number of Topics = 12  has Coherence Value of 0.5435\n",
            "Number of Topics = 14  has Coherence Value of 0.4458\n",
            "Number of Topics = 16  has Coherence Value of 0.4881\n",
            "Number of Topics = 18  has Coherence Value of 0.4823\n",
            "Number of Topics = 20  has Coherence Value of 0.5115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(cohe_val)/len(cohe_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAamLxBRPSa0",
        "outputId": "f7b5e928-b506-4ba2-a94f-97db4fec68bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42489"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal = model_[2] # getting the topics=6 model, which is in 2nd index of our model and getting the 6 topics.\n",
        "topics = optimal.show_topics(formatted=False)\n",
        "pprint(optimal.print_topics(num_words=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khyrpTAGX23g",
        "outputId": "45a87886-2d0e-4b1d-e376-f9ee94a0df98"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.028*\"car\" + 0.021*\"sharing\" + 0.021*\"need\" + 0.021*\"city\" + '\n",
            "  '0.021*\"electric\" + 0.014*\"transportation\" + 0.014*\"also\" + '\n",
            "  '0.014*\"community\" + 0.014*\"sustainable\" + 0.014*\"vehicle\"'),\n",
            " (1,\n",
            "  '0.025*\"mobility\" + 0.025*\"sustainable\" + 0.015*\"infrastructure\" + '\n",
            "  '0.015*\"solution\" + 0.015*\"reduce\" + 0.015*\"sharing\" + 0.015*\"car\" + '\n",
            "  '0.011*\"role\" + 0.011*\"datum\" + 0.011*\"make\"'),\n",
            " (2,\n",
            "  '0.035*\"sustainable\" + 0.028*\"mobility\" + 0.024*\"solution\" + '\n",
            "  '0.016*\"transportation\" + 0.012*\"friendly\" + 0.012*\"urban\" + 0.012*\"future\" '\n",
            "  '+ 0.012*\"sharing\" + 0.012*\"car\" + 0.012*\"community\"'),\n",
            " (3,\n",
            "  '0.025*\"solution\" + 0.014*\"alternative\" + 0.014*\"travel\" + 0.014*\"short\" + '\n",
            "  '0.014*\"distance\" + 0.014*\"policy\" + 0.014*\"infrastructure\" + '\n",
            "  '0.014*\"provide\" + 0.014*\"conscious\" + 0.014*\"design\"'),\n",
            " (4,\n",
            "  '0.031*\"transportation\" + 0.025*\"electric\" + 0.019*\"sustainable\" + '\n",
            "  '0.019*\"vehicle\" + 0.019*\"bus\" + 0.019*\"friendly\" + 0.013*\"option\" + '\n",
            "  '0.013*\"service\" + 0.013*\"urban\" + 0.013*\"sharing\"'),\n",
            " (5,\n",
            "  '0.018*\"sustainable\" + 0.018*\"public\" + 0.018*\"transportation\" + '\n",
            "  '0.018*\"electric\" + 0.018*\"also\" + 0.010*\"efficiency\" + 0.010*\"technology\" + '\n",
            "  '0.010*\"drive\" + 0.010*\"solution\" + 0.010*\"challenge\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "\n",
        "**Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92798bb2-cd26-4b58-b73d-57dcc04a5d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in 0: 0.387*\"sustainable\" + 0.292*\"mobility\" + 0.291*\"transportation\" + 0.266*\"car\" + 0.251*\"sharing\" + 0.245*\"electric\" + 0.241*\"solution\" + 0.163*\"vehicle\" + 0.158*\"urban\" + 0.144*\"bus\".\n",
            "Words in 1: -0.427*\"sustainable\" + -0.392*\"mobility\" + 0.276*\"transportation\" + 0.245*\"electric\" + 0.209*\"car\" + 0.200*\"bus\" + 0.179*\"sharing\" + -0.176*\"solution\" + 0.176*\"vehicle\" + -0.169*\"community\".\n",
            "Words in 2: 0.373*\"bus\" + -0.328*\"car\" + -0.274*\"sharing\" + 0.211*\"electric\" + -0.187*\"need\" + 0.165*\"friendly\" + 0.160*\"city\" + -0.152*\"service\" + 0.137*\"public\" + 0.135*\"alternative\".\n",
            "Words in 3: -0.272*\"solution\" + -0.216*\"community\" + -0.193*\"engagement\" + -0.177*\"enable\" + -0.176*\"initiative\" + -0.165*\"strategy\" + 0.162*\"sustainable\" + -0.153*\"insight\" + -0.153*\"local\" + -0.153*\"authority\".\n",
            "Words in 4: 0.265*\"community\" + -0.247*\"solution\" + 0.215*\"friendly\" + 0.176*\"need\" + -0.170*\"datum\" + 0.157*\"environmentally\" + -0.145*\"battery\" + -0.144*\"urban\" + 0.143*\"vehicle\" + 0.140*\"alternative\".\n",
            "Words in 5: -0.225*\"city\" + -0.225*\"datum\" + -0.202*\"clean\" + -0.176*\"effective\" + -0.172*\"also\" + -0.171*\"environment\" + 0.153*\"battery\" + 0.151*\"infrastructure\" + 0.150*\"solution\" + 0.140*\"electric\".\n",
            "Words in 6: 0.301*\"development\" + 0.252*\"continue\" + 0.191*\"community\" + 0.155*\"also\" + -0.145*\"policy\" + 0.141*\"drive\" + 0.140*\"technology\" + 0.138*\"research\" + -0.136*\"benefit\" + -0.136*\"encourage\".\n",
            "Words in 7: -0.201*\"efficiency\" + -0.200*\"technology\" + 0.181*\"car\" + -0.179*\"integration\" + 0.170*\"reduce\" + -0.163*\"furthermore\" + 0.148*\"pollution\" + -0.145*\"initiative\" + 0.142*\"make\" + -0.134*\"user\".\n",
            "Words in 8: 0.266*\"alternative\" + 0.262*\"urban\" + 0.240*\"distance\" + 0.240*\"short\" + 0.179*\"provide\" + 0.171*\"convenient\" + 0.148*\"effective\" + 0.147*\"travel\" + -0.147*\"bus\" + -0.146*\"also\".\n",
            "Words in 9: 0.235*\"drive\" + -0.202*\"integration\" + 0.195*\"option\" + -0.194*\"also\" + 0.174*\"datum\" + 0.161*\"transportation\" + -0.119*\"way\" + -0.119*\"pave\" + -0.119*\"investment\" + 0.115*\"accessibility\".\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "from gensim.models import LsiModel #we are importing lsi model from gensim class\n",
        "lsa_model = LsiModel(corpus,  num_topics=10,\n",
        "id2word=review_word ) # mapping the id to the words\n",
        "for topic_num, wo in lsa_model.print_topics(num_words=10):\n",
        "    print('Words in {}: {}.'.format(topic_num, wo))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lsa_coherence_value(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    lsa_coh_val = []\n",
        "    model_lsa = []\n",
        "    for num_topics in range(start, stop, step):\n",
        "        lsa_model = LsiModel(corpus, num_topics=num_topics, id2word = dictionary)\n",
        "        model_lsa.append(lsa_model)\n",
        "        coh_model = CoherenceModel(model=lsa_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        lsa_coh_val.append(coh_model.get_coherence())\n",
        "\n",
        "    return model_lsa, lsa_coh_val\n",
        "\n",
        "start,stop,step=2,20,2\n",
        "model_lsa, lsa_coh_val =lsa_coherence_value(dictionary=review_word, corpus=corpus, texts=lemm_data,\n",
        "                                            start=start, limit=limit, step=step)\n",
        "all_coh_val = []\n",
        "for m, cv in zip(range(start, limit, step), lsa_coh_val):\n",
        "    all_coh_val.append(round(cv,4))\n",
        "    print(\"Topic\", m, \"=\",\" Coherence Value is\", round(cv, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3ARuGVm-RDf",
        "outputId": "684ca832-9b91-436e-89eb-940b8c3f8a3f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 2 =  Coherence Value is 0.4002\n",
            "Topic 4 =  Coherence Value is 0.5445\n",
            "Topic 6 =  Coherence Value is 0.4039\n",
            "Topic 8 =  Coherence Value is 0.3949\n",
            "Topic 10 =  Coherence Value is 0.4677\n",
            "Topic 12 =  Coherence Value is 0.4613\n",
            "Topic 14 =  Coherence Value is 0.4182\n",
            "Topic 16 =  Coherence Value is 0.4253\n",
            "Topic 18 =  Coherence Value is 0.4236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coherencemodel_lsa = CoherenceModel(model=lsa_model, texts=lemm_data, dictionary=review_word, coherence='c_v')\n",
        "print(coherencemodel_lsa.get_coherence())\n",
        "print(\"coherence values for all :\",all_coh_val )\n",
        "avg_lsa_coh_val= sum(all_coh_val) / len(all_coh_val)\n",
        "print(\"Average Coherence Value for LSA:\", avg_lsa_coh_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE3DnZRT-RJv",
        "outputId": "75f20cf6-f789-43f1-fa33-f4b691024284"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.40058082554461105\n",
            "coherence values for all : [0.4002, 0.5445, 0.4039, 0.3949, 0.4677, 0.4613, 0.4182, 0.4253, 0.4236]\n",
            "Average Coherence Value for LSA: 0.4377333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NixZASvCEPEx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "**Generate K topics by using lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b1580b-1c79-4fde-d291-f058289cb20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: preprocess in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from preprocess) (0.18.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "nltk.download('all')\n",
        "!pip install preprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import pyLDAvis\n",
        "pyLDAvis.enable_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "pyLDAvis.enable_notebook()\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec = CountVectorizer()#initializing count vectorizer\n",
        "x= vec.fit_transform(text)\n",
        "\n",
        "# Get the top words for each topic\n",
        "count = 10\n",
        "topwords_in_topic= {}\n",
        "for k in range(x.shape[0]):\n",
        "  word_index = np.argsort(x[k].toarray()[0])[::-1][:count]\n",
        "  topword = [vec.get_feature_names_out()[i] for i in word_index]\n",
        "  out = 'Top 10 words in topic %i : %s' % (k, ', '.join(topword))\n",
        "  print(out)\n",
        "  topwords_in_topic[k] = topword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFKUnj__MgDC",
        "outputId": "ccf59af0-9398-4234-f15f-3b20ceeba0ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words in topic 0 : recent, emphasis, footprint, carbon, surrounding, sustainability, global, growing, conversation, reducing\n",
            "Top 10 words in topic 1 : mobility, known, urban, contribution, surge, micro, significant, reshaping, player, car\n",
            "Top 10 words in topic 2 : eco, public, transportation, bus, electric, friendly, backbone, extend, experience, energy\n",
            "Top 10 words in topic 3 : bus, counterpart, environmentally, guzzling, gas, bustling, traditional, hum, fundamental, friendly\n",
            "Top 10 words in topic 4 : zero, emitting, tailpipe, making, tackling, bus, solution, run, pollution, emission\n",
            "Top 10 words in topic 5 : provide, network, ride, result, bus, smoother, contribute, transportation, passenger, remarkable\n",
            "Top 10 words in topic 6 : battery, significantly, potential, capability, improved, bus, electric, regarding, advancement, addressing\n",
            "Top 10 words in topic 7 : driving, sharing, car, future, sustainable, towards, effective, effectiveness, ensure, environment\n",
            "Top 10 words in topic 8 : option, car, rise, convenient, cost, continue, swell, transportation, led, population\n",
            "Top 10 words in topic 9 : car, access, needed, basis, enable, personal, sharing, eliminating, program, vehicle\n",
            "Top 10 words in topic 10 : initiative, vital, play, encouraging, resource, mobility, sustainable, sharing, role, car\n",
            "Top 10 words in topic 11 : space, user, lower, cost, extend, beyond, minimized, traffic, requirement, transportation\n",
            "Top 10 words in topic 12 : need, vehicle, car, alternative, transportation, friendly, electric, user, bolstered, furthermore\n",
            "Top 10 words in topic 13 : redefining, travel, micro, mobility, short, distance, extend, environmental, energy, engagement\n",
            "Top 10 words in topic 14 : emergence, bustling, witnessed, city, micro, mobility, new, mode, center, street\n",
            "Top 10 words in topic 15 : electric, encompasses, scooter, lightweight, transport, bicycle, mode, term, various, even\n",
            "Top 10 words in topic 16 : eco, short, solution, area, travel, alternative, urban, convenient, conscious, congested\n",
            "Top 10 words in topic 17 : rising, friendly, option, popularity, attributed, micro, mobility, nature, user, accessibility\n",
            "Top 10 words in topic 18 : daily, dependence, traditional, transportation, lessening, traversing, alternative, mean, short, method\n",
            "Top 10 words in topic 19 : resonates, urban, curbing, emission, development, focus, moreover, eco, fostering, increasing\n",
            "Top 10 words in topic 20 : role, policy, infrastructure, mobility, promoting, sustainable, environmentally, encouraging, energy, engagement\n",
            "Top 10 words in topic 21 : heavily, relies, mobility, sustainable, conducive, effectiveness, supportive, policy, solution, infrastructure\n",
            "Top 10 words in topic 22 : solution, designed, policy, contingent, positive, appropriate, success, proliferation, presence, step\n",
            "Top 10 words in topic 23 : eco, vehicle, implementation, dedicated, transportation, lane, along, electric, charging, developing\n",
            "Top 10 words in topic 24 : sustainable, influence, transition, tax, behavior, benefit, furthermore, strategy, car, mobility\n",
            "Top 10 words in topic 25 : opportunity, challenge, horizon, zero, ever, engagement, enhance, ensure, environment, environmental\n",
            "Top 10 words in topic 26 : solution, sustainable, benefit, widespread, despite, mobility, challenge, evident, implementation, persist\n",
            "Top 10 words in topic 27 : comprehensive, regulatory, micro, govern, cost, technological, car, continued, need, challenge\n",
            "Top 10 words in topic 28 : present, opportunity, innovation, within, also, public, sector, collaboration, challenge, however\n",
            "Top 10 words in topic 29 : fabric, partnership, sustainable, community, mobility, coupled, business, life, research, seamless\n",
            "Top 10 words in topic 30 : sustainable, motion, future, ever, engagement, enhance, ensure, environment, environmental, environmentally\n",
            "Top 10 words in topic 31 : ever, evident, become, solution, loom, environmental, sustainable, impact, importance, era\n",
            "Top 10 words in topic 32 : cleaner, sharing, benefiting, mobility, bus, capability, car, city, people, transportation\n",
            "Top 10 words in topic 33 : role, requires, sector, positive, mobility, sustainable, towards, journey, various, effort\n",
            "Top 10 words in topic 34 : innovation, pave, environmentally, mobility, sustainable, continued, also, conscious, advocacy, future\n",
            "Top 10 words in topic 35 : steer, vibrant, city, sustainable, together, tomorrow, toward, effective, encouraging, engagement\n",
            "Top 10 words in topic 36 : engagement, education, community, empowering, zero, ever, enhance, ensure, environment, environmental\n",
            "Top 10 words in topic 37 : engagement, fostering, sustainable, empowerment, cornerstone, successful, mobility, form, community, education\n",
            "Top 10 words in topic 38 : instrumental, transportation, educational, program, culture, cultivating, encouraging, campaign, sustainability, habit\n",
            "Top 10 words in topic 39 : environmentally, impact, environment, alternative, benefit, transition, mobility, sustainable, towards, friendly\n",
            "Top 10 words in topic 40 : enabling, transportation, policymaker, authority, resident, local, platform, tailor, gathering, engagement\n",
            "Top 10 words in topic 41 : community, incorporating, centric, planning, sustainable, ensure, mobility, also, project, inclusive\n",
            "Top 10 words in topic 42 : sustainable, looking, mobility, evolution, ahead, zero, engagement, enhance, ensure, environment\n",
            "Top 10 words in topic 43 : societal, evolution, awareness, grow, mobility, continues, sustainable, environmental, poised, landscape\n",
            "Top 10 words in topic 44 : field, performance, technology, sustainable, source, expected, option, significant, continued, transportation\n",
            "Top 10 words in topic 45 : driven, car, hold, optimize, furthermore, micro, enhance, mobility, streamline, data\n",
            "Top 10 words in topic 46 : data, city, decision, mobility, sustainable, make, contributing, resilient, environment, leveraging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "**Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bertopic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FadAUy-OIhsX",
        "outputId": "59c84936-6d49-4f74-d2c9-7bc3a16506d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.25.2)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.33)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.6.1)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.15.0)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.37)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.38.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (9.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.58.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.10.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "012b5ce92e7044199005d5607c2d7c4b",
            "8cd1f90929314837b803f3734fa598bf",
            "9e9812b878594e80ba48fcc720b0d922",
            "3d9cab6b969b4683a076222c63a872a0",
            "26541184513b41889e0923960af592c1",
            "5bc77ac63e95454a8354282e676ce639",
            "dac11b5276d443ea8e6c0c7c3981f172",
            "56a2868057c9457299e365edf477b840",
            "9c4b4f51392749228165386598350f2f",
            "5398b99bd7154df58de406688404bf6f",
            "9556c436a61e453b9ad30227f96fefb4"
          ]
        },
        "outputId": "b86a196f-71ff-4bcd-8dfb-d60defe62eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-30 03:17:54,557 - BERTopic - Embedding - Transforming documents to embeddings.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "012b5ce92e7044199005d5607c2d7c4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-30 03:17:59,145 - BERTopic - Embedding - Completed ✓\n",
            "2024-03-30 03:17:59,148 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
            "2024-03-30 03:18:09,565 - BERTopic - Dimensionality - Completed ✓\n",
            "2024-03-30 03:18:09,566 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
            "2024-03-30 03:18:09,576 - BERTopic - Cluster - Completed ✓\n",
            "2024-03-30 03:18:09,578 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
            "2024-03-30 03:18:09,594 - BERTopic - Representation - Completed ✓\n",
            "2024-03-30 03:18:09,596 - BERTopic - Topic reduction - Reducing number of topics\n",
            "2024-03-30 03:18:09,619 - BERTopic - Topic reduction - Reduced number of topics from 3 to 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: electric, transportation, bus, sharing, car, vehicle, mobility, efficiency, service, user (Freq: 16)\n",
            "Topic -1: distance, short, car, transportation, micro, mobility, travel, encouraging, program, individual (Freq: 12)\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "from bertopic import BERTopic\n",
        "\n",
        "bert_model = BERTopic(nr_topics=\"auto\", calculate_probabilities=True, verbose=True)\n",
        "topic, _ = bert_model.fit_transform(text)\n",
        "\n",
        "overview = bert_model.get_topic_freq()\n",
        "\n",
        "for num, freq in overview[1:].values:\n",
        "    bert_words = bert_model.get_topic(num)\n",
        "    bert_summary = \", \".join([word[0] for word in bert_words[:10]])\n",
        "    print(f\"Topic {num}: {bert_summary} (Freq: {freq})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Question (5 Points)\n",
        "\n",
        "**Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.**\n",
        "\n",
        "**This question will compensate for any points deducted in this exercise. Maximum marks for the exercise is 40 points.**"
      ],
      "metadata": {
        "id": "d89ODUx3jjJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After comparing the results,LSA is superior at identifying the semantic links between words, whereas LDA provides coherent and unambiguous concept renderings. On the other hand, lda2vec achieves the right balance between comprehension and recording intricate topic associations by combining the positive aspects of integrating words and LDA for more in-depth topic representations. However, the BERT model offers exceptionally integrated and adaptable to context subjects, which is particularly advantageous when understanding contextually is essential. . When all factors are taken into account, the BERT modelform is efficient because of its reliability and accessibility to several topic modeling variations"
      ],
      "metadata": {
        "id": "KIHf_fJcaCmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "Consider the following points in your response:\n",
        "\n",
        "**Learning Experience:** Describe your overall learning experience in working with text data and extracting features using various topic modeling algorithms. Did you understand these algorithms and did the implementations helped in grasping the nuances of feature extraction from text data.\n",
        "\n",
        "**Challenges Encountered:** Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By working on this exercise, I have learned about the how meaningful topics are extracted from documents by using various topic modeling algorithms. One particular challenge that I encountered while doing this exercise is understanding how the algorithm works internally I felt that it is very complex and also it is difficult for me to choose the set of parameters for the model to perform efficiently."
      ],
      "metadata": {
        "id": "ZcZhqLwldP4M"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "012b5ce92e7044199005d5607c2d7c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cd1f90929314837b803f3734fa598bf",
              "IPY_MODEL_9e9812b878594e80ba48fcc720b0d922",
              "IPY_MODEL_3d9cab6b969b4683a076222c63a872a0"
            ],
            "layout": "IPY_MODEL_26541184513b41889e0923960af592c1"
          }
        },
        "8cd1f90929314837b803f3734fa598bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bc77ac63e95454a8354282e676ce639",
            "placeholder": "​",
            "style": "IPY_MODEL_dac11b5276d443ea8e6c0c7c3981f172",
            "value": "Batches: 100%"
          }
        },
        "9e9812b878594e80ba48fcc720b0d922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a2868057c9457299e365edf477b840",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c4b4f51392749228165386598350f2f",
            "value": 2
          }
        },
        "3d9cab6b969b4683a076222c63a872a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5398b99bd7154df58de406688404bf6f",
            "placeholder": "​",
            "style": "IPY_MODEL_9556c436a61e453b9ad30227f96fefb4",
            "value": " 2/2 [00:02&lt;00:00,  1.00s/it]"
          }
        },
        "26541184513b41889e0923960af592c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bc77ac63e95454a8354282e676ce639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac11b5276d443ea8e6c0c7c3981f172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56a2868057c9457299e365edf477b840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c4b4f51392749228165386598350f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5398b99bd7154df58de406688404bf6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9556c436a61e453b9ad30227f96fefb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}